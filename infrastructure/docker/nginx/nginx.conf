worker_processes auto;

events {
    worker_connections 1024;
}

http {
    # ─── Rate Limiting ────────────────────────────────────────────────
    # Per-IP request rate limiting (token bucket algorithm)
    # 100 requests/second per IP address — stops volumetric abuse before
    # it reaches the application layer. NestJS adds per-user throttling
    # on the purchase endpoint as a second line of defense.
    limit_req_zone $binary_remote_addr zone=api:10m rate=100r/s;

    # Per-IP connection limiting — protects against connection exhaustion,
    # especially important for SSE endpoints that hold long-lived connections.
    limit_conn_zone $binary_remote_addr zone=addr:10m;

    # ─── CDN Layer Placement (NF-12) ─────────────────────────────────
    # In production, a CDN (e.g., CloudFront, Cloudflare) would sit in
    # front of Nginx to:
    #   1. Cache GET /api/v1/sales/:sku/status responses (1s TTL)
    #      — absorbs polling storms during flash sales
    #   2. Terminate TLS closer to end users
    #   3. Provide geographic distribution
    #   4. Add an additional DDoS mitigation layer
    #
    # Architecture: Client → CDN → Nginx → NestJS API
    #
    # The Cache-Control headers are set by the NestJS application (PR8)
    # to enable CDN caching without Nginx configuration changes.
    # ─────────────────────────────────────────────────────────────────

    upstream backend {
        server api:3000;
    }

    server {
        listen 80;
        server_name _;

        # Apply rate limiting — allow small bursts (10 requests) to handle
        # legitimate rapid interactions without penalizing real users.
        limit_req zone=api burst=10 nodelay;

        # Max 5 concurrent connections per IP — prevents a single client
        # from monopolizing server resources via parallel SSE streams.
        limit_conn addr 5;

        # Standard rate limit response
        limit_req_status 429;
        limit_conn_status 429;

        location / {
            proxy_pass http://backend;

            # Preserve original client information for logging and per-user throttling
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;

            # ─── SSE Support ─────────────────────────────────────
            # Server-Sent Events require disabling buffering so that
            # events are flushed to the client immediately rather than
            # being batched by Nginx's output buffer.
            proxy_buffering off;
            proxy_cache off;

            # SSE connections are long-lived — prevent Nginx from
            # closing them prematurely. 1 hour matches the maximum
            # expected flash sale duration.
            proxy_read_timeout 3600s;
            proxy_send_timeout 3600s;
        }
    }
}
